{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anshoo Mehra\n",
    "\n",
    "Credit: Udacity\n",
    "\n",
    "# Transfer Learning Quick Guide\n",
    "\n",
    "Transfer learning involves taking a pre-trained neural network and adapting the neural network to a new, different data set.\n",
    "\n",
    "Depending on both:\n",
    "\n",
    "- the size of the new data set, and\n",
    "- the similarity of the new data set to the original data set\n",
    "\n",
    "The approach for using transfer learning will be different. There are four main cases:\n",
    "\n",
    "- new data set is small, new data is similar to original training data - **End Of Covnet**\n",
    "- new data set is small, new data is different from original training data **Fine Tune**\n",
    "- new data set is large, new data is similar to original training data **Fine Tune & Re-Train**\n",
    "- new data set is large, new data is different from original training data **Start of Covnet**\n",
    "\n",
    "**End Of Covnet**\n",
    "If the new data set is small and similar to the original training data:\n",
    "\n",
    "- slice off the end of the neural network\n",
    "- add a new fully connected layer that matches the number of classes in the new data set\n",
    "- randomize the weights of the new fully connected layer; freeze all the weights from the pre-trained network\n",
    "- train the network to update the weights of the new fully connected layer\n",
    "\n",
    "To avoid overfitting on the small data set, the weights of the original network will be held constant rather than re-training the weights.\n",
    "\n",
    "Since the data sets are similar, images from each data set will have similar higher level features. Therefore most or all of the pre-trained neural network layers already contain relevant information about the new data set and should be kept.\n",
    "\n",
    "**Start of Covnet**\n",
    "\n",
    "If the new data set is small and different from the original training data:\n",
    "\n",
    "- slice off most of the pre-trained layers near the beginning of the network\n",
    "- add to the remaining pre-trained layers a new fully connected layer that matches the number of classes in the new data set\n",
    "- randomize the weights of the new fully connected layer; freeze all the weights from the pre-trained network\n",
    "- train the network to update the weights of the new fully connected layer\n",
    "\n",
    "Because the data set is small, overfitting is still a concern. To combat overfitting, the weights of the original neural network will be held constant, like in the first case.\n",
    "\n",
    "But the original training set and the new data set do not share higher level features. In this case, the new network will only use the layers containing lower level features.\n",
    "\n",
    "**Fine Tune**\n",
    "\n",
    "If the new data set is large and similar to the original training data:\n",
    "\n",
    "- remove the last fully connected layer and replace with a layer matching the number of classes in the new data set\n",
    "- randomly initialize the weights in the new fully connected layer\n",
    "- initialize the rest of the weights using the pre-trained weights\n",
    "- re-train the entire neural network\n",
    "\n",
    "Overfitting is not as much of a concern when training on a large data set; therefore, you can re-train all of the weights.\n",
    "\n",
    "Because the original training set and the new data set share higher level features, the entire neural network is used as well.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Fine Tune & Re-Train**\n",
    "\n",
    "If the new data set is large and different from the original training data:\n",
    "\n",
    "- remove the last fully connected layer and replace with a layer matching the number of classes in the new data set\n",
    "- retrain the network from scratch with randomly initialized weights\n",
    "- alternatively, you could just use the same strategy as the \"large and similar\" data case\n",
    "\n",
    "Even though the data set is different from the training data, initializing the weights from the pre-trained network might make training faster. So this case is exactly the same as the case with a large, similar data set.\n",
    "\n",
    "If using the pre-trained network as a starting point does not produce a successful model, another option is to randomly initialize the convolutional neural network weights and train the network from scratch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things to Study : LeNet, AlexNet\n",
    "\n",
    "http://yann.lecun.com/exdb/lenet/ (1998)\n",
    "\n",
    "https://en.wikipedia.org/wiki/AlexNet (2012)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we apply transfer learning? Two popular methods are feature extraction and finetuning.\n",
    "\n",
    "**Feature extraction.** Take a pretrained neural network and replace the final (classification) layer with a new classification layer, or perhaps even a small feedforward network that ends with a new classification layer. During training the weights in all the pre-trained layers are frozen, so only the weights for the new layer(s) are trained. In other words, the gradient doesn't flow backwards past the first new layer.\n",
    "\n",
    "**Finetuning.** This is similar to feature extraction except the pre-trained weights aren't frozen. The network is trained end-to-end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNet is trained Imagenet Database so let's see example of how well it is Identifying Animal Classes (Poodle, Weasle) from Caffee Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0\n",
      "miniature poodle: 0.389\n",
      "toy poodle: 0.223\n",
      "Bedlington terrier: 0.173\n",
      "standard poodle: 0.150\n",
      "komondor: 0.026\n",
      "\n",
      "Image 1\n",
      "weasel: 0.331\n",
      "polecat, fitch, foulmart, foumart, Mustela putorius: 0.280\n",
      "black-footed ferret, ferret, Mustela nigripes: 0.210\n",
      "mink: 0.081\n",
      "Arctic fox, white fox, Alopex lagopus: 0.027\n",
      "\n",
      "Time: 0.126 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.misc import imread\n",
    "from caffe_classes import class_names\n",
    "from alexnet import AlexNet\n",
    "\n",
    "\n",
    "# placeholders\n",
    "x = tf.placeholder(tf.float32, (None, 227, 227, 3))\n",
    "\n",
    "# By keeping `feature_extract` set to `False`\n",
    "# we indicate to keep the 1000 class final layer\n",
    "# originally used to train on ImageNet.\n",
    "probs = AlexNet(x, feature_extract=False)\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Read Images\n",
    "im1 = (imread(\"poodle.png\")[:, :, :3]).astype(np.float32)\n",
    "im1 = im1 - np.mean(im1)\n",
    "\n",
    "im2 = (imread(\"weasel.png\")[:, :, :3]).astype(np.float32)\n",
    "im2 = im2 - np.mean(im2)\n",
    "\n",
    "# Run Inference\n",
    "t = time.time()\n",
    "output = sess.run(probs, feed_dict={x: [im1, im2]})\n",
    "\n",
    "# Print Output\n",
    "for input_im_ind in range(output.shape[0]):\n",
    "    inds = np.argsort(output)[input_im_ind, :]\n",
    "    print(\"Image\", input_im_ind)\n",
    "    for i in range(5):\n",
    "        print(\"%s: %.3f\" % (class_names[inds[-1 - i]], output[input_im_ind, inds[-1 - i]]))\n",
    "    print()\n",
    "\n",
    "print(\"Time: %.3f seconds\" % (time.time() - t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's see if we apply past learning of ImageNet database on Traffic Signs how well it performs .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Image 0\n",
      "screen, CRT screen: 0.051\n",
      "digital clock: 0.041\n",
      "laptop, laptop computer: 0.030\n",
      "balance beam, beam: 0.027\n",
      "parallel bars, bars: 0.023\n",
      "\n",
      "Image 1\n",
      "digital watch: 0.395\n",
      "digital clock: 0.275\n",
      "bottlecap: 0.115\n",
      "stopwatch, stop watch: 0.104\n",
      "combination lock: 0.086\n",
      "\n",
      "Time: 0.106 seconds\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The traffic signs are 32x32 so you\n",
    "have to resize them to be 227x227 before\n",
    "passing them to AlexNet.\n",
    "\"\"\"\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.misc import imread\n",
    "from caffe_classes import class_names\n",
    "from alexnet import AlexNet\n",
    "\n",
    "\n",
    "# placeholders\n",
    "x = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "resized = tf.image.resize_images(x, (227, 227))\n",
    "\n",
    "probs = AlexNet(resized)\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Read Images\n",
    "im1 = imread(\"construction.jpg\").astype(np.float32)\n",
    "im1 = im1 - np.mean(im1)\n",
    "\n",
    "im2 = imread(\"stop.jpg\").astype(np.float32)\n",
    "im2 = im2 - np.mean(im2)\n",
    "\n",
    "# Run Inference\n",
    "t = time.time()\n",
    "output = sess.run(probs, feed_dict={x: [im1, im2]})\n",
    "\n",
    "# Print Output\n",
    "for input_im_ind in range(output.shape[0]):\n",
    "    inds = np.argsort(output)[input_im_ind, :]\n",
    "    print(\"Image\", input_im_ind)\n",
    "    for i in range(5):\n",
    "        print(\"%s: %.3f\" % (class_names[inds[-1 - i]], output[input_im_ind, inds[-1 - i]]))\n",
    "    print()\n",
    "\n",
    "print(\"Time: %.3f seconds\" % (time.time() - t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offcourse it is not peforming well, so we will apply feature extraction ..\n",
    "\n",
    "**Feature Extraction**\n",
    "The problem is that AlexNet was trained on the ImageNet database, which has 1000 classes of images. You can see the classes in the caffe_classes.py file. None of those classes involves traffic signs.\n",
    "\n",
    "In order to successfully classify our traffic sign images, you need to remove the final, 1000-neuron classification layer and replace it with a new, 43-neuron classification layer.\n",
    "\n",
    "This is called feature extraction, because you're basically extracting the image features inferred by the penultimate layer, and passing these features to a new classification layer.\n",
    "\n",
    "Your output will probably not precisely match the sample output below, since the output will depend on the (probably random) initialization of weights in the network. That being said, the output classes you see should be present in signnames.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Image 0\n",
      "Traffic signals: 0.064\n",
      "Speed limit (60km/h): 0.051\n",
      "Speed limit (120km/h): 0.043\n",
      "Wild animals crossing: 0.040\n",
      "Stop: 0.040\n",
      "\n",
      "Image 1\n",
      "Roundabout mandatory: 0.065\n",
      "Children crossing: 0.059\n",
      "Speed limit (60km/h): 0.057\n",
      "Double curve: 0.043\n",
      "Speed limit (120km/h): 0.042\n",
      "\n",
      "Time: 0.125 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "from alexnet import AlexNet\n",
    "\n",
    "sign_names = pd.read_csv('signnames.csv')\n",
    "nb_classes = 43\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "resized = tf.image.resize_images(x, (227, 227))\n",
    "\n",
    "# Returns the second final layer of the AlexNet model,\n",
    "# this allows us to redo the last layer specifically for \n",
    "# traffic signs model.\n",
    "fc7 = AlexNet(resized, feature_extract=True)\n",
    "shape = (fc7.get_shape().as_list()[-1], nb_classes)\n",
    "fc8W = tf.Variable(tf.truncated_normal(shape, stddev=1e-2))\n",
    "fc8b = tf.Variable(tf.zeros(nb_classes))\n",
    "logits = tf.nn.xw_plus_b(fc7, fc8W, fc8b)\n",
    "probs = tf.nn.softmax(logits)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Read Images\n",
    "im1 = imread(\"construction.jpg\").astype(np.float32)\n",
    "im1 = im1 - np.mean(im1)\n",
    "\n",
    "im2 = imread(\"stop.jpg\").astype(np.float32)\n",
    "im2 = im2 - np.mean(im2)\n",
    "\n",
    "# Run Inference\n",
    "t = time.time()\n",
    "output = sess.run(probs, feed_dict={x: [im1, im2]})\n",
    "\n",
    "# Print Output\n",
    "for input_im_ind in range(output.shape[0]):\n",
    "    inds = np.argsort(output)[input_im_ind, :]\n",
    "    print(\"Image\", input_im_ind)\n",
    "    for i in range(5):\n",
    "        print(\"%s: %.3f\" % (sign_names.ix[inds[-1 - i]][1], output[input_im_ind, inds[-1 - i]]))\n",
    "    print()\n",
    "\n",
    "print(\"Time: %.3f seconds\" % (time.time() - t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I figure out the shape of the final fully connected layer, in my opinion this is the trickiest part. To do that I have to figure out the size of the output from fc7. Since it's a fully connected layer I know it's shape will be 2D so the second (or last) element of the list will be the size of the output. fc7.get_shape().as_list()[-1] does the trick. I then combine this with the number of classes for the Traffic Sign dataset to get the shape of the final fully connected layer, shape = (fc7.get_shape().as_list()[-1], nb_classes). The rest of the code is just the standard way to define a fully connected in TensorFlow. Finally, I calculate the probabilities via softmax, probs = tf.nn.softmax(logits).\n",
    "\n",
    "**Training the Feature Extractor**\n",
    "The feature extractor you just created works, in the sense that data will flow through the network and result in predictions.\n",
    "\n",
    "But the predictions aren't accurate, because you haven't yet trained the new classification layer.\n",
    "\n",
    "In order to do that, you'll need to read in the training dataset and train the network.\n",
    "\n",
    "Training AlexNet (even just the final layer!) can take a little while, so if you don't have a GPU, running on a subset of the data is a good alternative. As a point of reference one epoch over the training set takes roughly 53-55 seconds with a GTX 970."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "WARNING:tensorflow:From <ipython-input-9-7053f3a8c949>:38: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "Epoch 1\n",
      "Time: 1098.138 seconds\n",
      "Validation Loss = 0.513324991621\n",
      "Validation Accuracy = 0.867145838187\n",
      "\n",
      "Epoch 2\n",
      "Time: 1223.846 seconds\n",
      "Validation Loss = 0.353884641375\n",
      "Validation Accuracy = 0.909807558539\n",
      "\n",
      "Epoch 3\n",
      "Time: 1052.179 seconds\n",
      "Validation Loss = 0.263128438049\n",
      "Validation Accuracy = 0.937166705305\n",
      "\n",
      "Epoch 4\n",
      "Time: 1070.928 seconds\n",
      "Validation Loss = 0.21622725981\n",
      "Validation Accuracy = 0.945590849393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from alexnet import AlexNet\n",
    "\n",
    "nb_classes = 43\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "with open('./train.p', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(data['features'], data['labels'], test_size=0.33, random_state=0)\n",
    "\n",
    "features = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "labels = tf.placeholder(tf.int64, None)\n",
    "resized = tf.image.resize_images(features, (227, 227))\n",
    "\n",
    "# Returns the second final layer of the AlexNet model,\n",
    "# this allows us to redo the last layer for the traffic signs\n",
    "# model.\n",
    "fc7 = AlexNet(resized, feature_extract=True)\n",
    "fc7 = tf.stop_gradient(fc7)\n",
    "shape = (fc7.get_shape().as_list()[-1], nb_classes)\n",
    "fc8W = tf.Variable(tf.truncated_normal(shape, stddev=1e-2))\n",
    "fc8b = tf.Variable(tf.zeros(nb_classes))\n",
    "logits = tf.nn.xw_plus_b(fc7, fc8W, fc8b)\n",
    "\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels)\n",
    "loss_op = tf.reduce_mean(cross_entropy)\n",
    "opt = tf.train.AdamOptimizer()\n",
    "train_op = opt.minimize(loss_op, var_list=[fc8W, fc8b])\n",
    "init_op = tf.initialize_all_variables()\n",
    "\n",
    "preds = tf.arg_max(logits, 1)\n",
    "accuracy_op = tf.reduce_mean(tf.cast(tf.equal(preds, labels), tf.float32))\n",
    "\n",
    "def eval_on_data(X, y, sess):\n",
    "    total_acc = 0\n",
    "    total_loss = 0\n",
    "    for offset in range(0, X.shape[0], batch_size):\n",
    "        end = offset + batch_size\n",
    "        X_batch = X[offset:end]\n",
    "        y_batch = y[offset:end]\n",
    "\n",
    "        loss, acc = sess.run([loss_op, accuracy_op], feed_dict={features: X_batch, labels: y_batch})\n",
    "        total_loss += (loss * X_batch.shape[0])\n",
    "        total_acc += (acc * X_batch.shape[0])\n",
    "\n",
    "    return total_loss/X.shape[0], total_acc/X.shape[0]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # training\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        t0 = time.time()\n",
    "        for offset in range(0, X_train.shape[0], batch_size):\n",
    "            end = offset + batch_size\n",
    "            sess.run(train_op, feed_dict={features: X_train[offset:end], labels: y_train[offset:end]})\n",
    "\n",
    "        val_loss, val_acc = eval_on_data(X_val, y_val, sess)\n",
    "        print(\"Epoch\", i+1)\n",
    "        print(\"Time: %.3f seconds\" % (time.time() - t0))\n",
    "        print(\"Validation Loss =\", val_loss)\n",
    "        print(\"Validation Accuracy =\", val_acc)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Even today AlexNet is very popular for computer vision. Though not all features were necessary, and hence there are various implementaion of AlexNet available today ..**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at other Networks which came after Alexnet \n",
    "\n",
    "## In 2014, VGGNet & GoogleLeNet almost tied with ImageNet Competition...\n",
    "\n",
    "** VGG ** has only 7.3% error classification ..\n",
    "\n",
    "** GoogLeNet ** has only 6.7% error classification .. It uses INCEPTION MODULE ( See NN Repo, as quick refresher it is combination module of various layers, Conv and Pooling etc .. So, it is combination module of Avg Pool >> 1x1 >> 1x1 >> 3x3 >> 1x1 >> 5x5 >> at top concatanate ouput, this helps keep total # of params small, and it runs as fast as AlexNet with high-accuracy, so it is great choice for real-time classification like self driving car .. \n",
    "\n",
    "## In 2015, ResNet by Microsoft won combination .. \n",
    "\n",
    "**ResNet** it has loss of only 3% which is better than human accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's try the CIFAR10 and GERMAN TRAFFIC SIGN DATABASES, before we go ahead, we will test classifier we just build on CIFAR10 and record our run as baseline .. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG Example .. Bottleneck Features are pre-trained to optimally run on CPU.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file vgg-100/vgg_cifar10_100_bottleneck_features_train.p\n",
      "Validation file vgg-100/vgg_cifar10_bottleneck_features_validation.p\n",
      "(1000, 1, 1, 512) (1000, 1)\n",
      "(10000, 1, 1, 512) (10000, 1)\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 0s - loss: 5.4451 - acc: 0.0960 - val_loss: 4.3878 - val_acc: 0.1151\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 0s - loss: 4.1390 - acc: 0.1380 - val_loss: 3.8769 - val_acc: 0.1373\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 0s - loss: 3.7073 - acc: 0.1670 - val_loss: 3.4681 - val_acc: 0.1736\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 0s - loss: 3.2241 - acc: 0.2000 - val_loss: 3.0008 - val_acc: 0.2240\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 0s - loss: 2.7447 - acc: 0.2540 - val_loss: 2.6268 - val_acc: 0.2700\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 0s - loss: 2.3743 - acc: 0.3140 - val_loss: 2.3581 - val_acc: 0.3147\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 0s - loss: 2.0899 - acc: 0.3610 - val_loss: 2.1298 - val_acc: 0.3563\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 0s - loss: 1.8430 - acc: 0.4200 - val_loss: 1.9287 - val_acc: 0.3988\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 0s - loss: 1.6441 - acc: 0.4700 - val_loss: 1.7727 - val_acc: 0.4329\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 0s - loss: 1.4856 - acc: 0.5070 - val_loss: 1.6529 - val_acc: 0.4649\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 0s - loss: 1.3523 - acc: 0.5350 - val_loss: 1.5535 - val_acc: 0.4974\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 0s - loss: 1.2443 - acc: 0.5700 - val_loss: 1.4738 - val_acc: 0.5212\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 0s - loss: 1.1513 - acc: 0.6000 - val_loss: 1.4078 - val_acc: 0.5376\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 0s - loss: 1.0725 - acc: 0.6250 - val_loss: 1.3495 - val_acc: 0.5546\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 0s - loss: 1.0035 - acc: 0.6480 - val_loss: 1.3033 - val_acc: 0.5697\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.9453 - acc: 0.6690 - val_loss: 1.2604 - val_acc: 0.5835\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.8912 - acc: 0.6940 - val_loss: 1.2259 - val_acc: 0.5923\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.8437 - acc: 0.7080 - val_loss: 1.1952 - val_acc: 0.6026\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.8021 - acc: 0.7230 - val_loss: 1.1689 - val_acc: 0.6128\n",
      "Epoch 20/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.7634 - acc: 0.7360 - val_loss: 1.1468 - val_acc: 0.6183\n",
      "Epoch 21/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.7288 - acc: 0.7500 - val_loss: 1.1241 - val_acc: 0.6255\n",
      "Epoch 22/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.6961 - acc: 0.7600 - val_loss: 1.1025 - val_acc: 0.6344\n",
      "Epoch 23/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.6667 - acc: 0.7710 - val_loss: 1.0839 - val_acc: 0.6414\n",
      "Epoch 24/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.6399 - acc: 0.7820 - val_loss: 1.0680 - val_acc: 0.6450\n",
      "Epoch 25/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.6140 - acc: 0.7950 - val_loss: 1.0567 - val_acc: 0.6494\n",
      "Epoch 26/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.5897 - acc: 0.8020 - val_loss: 1.0449 - val_acc: 0.6531\n",
      "Epoch 27/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.5678 - acc: 0.8150 - val_loss: 1.0316 - val_acc: 0.6588\n",
      "Epoch 28/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.5479 - acc: 0.8210 - val_loss: 1.0166 - val_acc: 0.6635\n",
      "Epoch 29/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.5263 - acc: 0.8320 - val_loss: 1.0066 - val_acc: 0.6678\n",
      "Epoch 30/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.5082 - acc: 0.8410 - val_loss: 1.0004 - val_acc: 0.6702\n",
      "Epoch 31/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.4902 - acc: 0.8490 - val_loss: 0.9903 - val_acc: 0.6727\n",
      "Epoch 32/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.4740 - acc: 0.8600 - val_loss: 0.9816 - val_acc: 0.6755\n",
      "Epoch 33/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.4588 - acc: 0.8640 - val_loss: 0.9740 - val_acc: 0.6776\n",
      "Epoch 34/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.4431 - acc: 0.8740 - val_loss: 0.9668 - val_acc: 0.6817\n",
      "Epoch 35/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.4288 - acc: 0.8780 - val_loss: 0.9600 - val_acc: 0.6847\n",
      "Epoch 36/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.4159 - acc: 0.8860 - val_loss: 0.9566 - val_acc: 0.6859\n",
      "Epoch 37/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.4032 - acc: 0.8880 - val_loss: 0.9491 - val_acc: 0.6899\n",
      "Epoch 38/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.3900 - acc: 0.8930 - val_loss: 0.9419 - val_acc: 0.6928\n",
      "Epoch 39/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.3787 - acc: 0.9020 - val_loss: 0.9380 - val_acc: 0.6931\n",
      "Epoch 40/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.3681 - acc: 0.9030 - val_loss: 0.9324 - val_acc: 0.6946\n",
      "Epoch 41/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.3562 - acc: 0.9080 - val_loss: 0.9272 - val_acc: 0.6975\n",
      "Epoch 42/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.3459 - acc: 0.9150 - val_loss: 0.9241 - val_acc: 0.6980\n",
      "Epoch 43/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.3365 - acc: 0.9200 - val_loss: 0.9218 - val_acc: 0.7000\n",
      "Epoch 44/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.3271 - acc: 0.9210 - val_loss: 0.9182 - val_acc: 0.7004\n",
      "Epoch 45/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.3177 - acc: 0.9290 - val_loss: 0.9133 - val_acc: 0.7017\n",
      "Epoch 46/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.3097 - acc: 0.9290 - val_loss: 0.9099 - val_acc: 0.7034\n",
      "Epoch 47/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.3011 - acc: 0.9310 - val_loss: 0.9064 - val_acc: 0.7050\n",
      "Epoch 48/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.2931 - acc: 0.9360 - val_loss: 0.9030 - val_acc: 0.7069\n",
      "Epoch 49/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.2852 - acc: 0.9390 - val_loss: 0.9017 - val_acc: 0.7080\n",
      "Epoch 50/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.2773 - acc: 0.9430 - val_loss: 0.8986 - val_acc: 0.7096\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "# command line flags\n",
    "# flags.DEFINE_string('training_file', '', \"Bottleneck features training file (.p)\")\n",
    "# flags.DEFINE_string('validation_file', '', \"Bottleneck features validation file (.p)\")\n",
    "# flags.DEFINE_integer('epochs', 50, \"The number of epochs.\")\n",
    "# flags.DEFINE_integer('batch_size', 256, \"The batch size.\")\n",
    "\n",
    "def load_bottleneck_data(training_file, validation_file):\n",
    "    \"\"\"\n",
    "    Utility function to load bottleneck features.\n",
    "\n",
    "    Arguments:\n",
    "        training_file - String\n",
    "        validation_file - String\n",
    "    \"\"\"\n",
    "    print(\"Training file\", training_file)\n",
    "    print(\"Validation file\", validation_file)\n",
    "\n",
    "    with open(training_file, 'rb') as f:\n",
    "        train_data = pickle.load(f)\n",
    "    with open(validation_file, 'rb') as f:\n",
    "        validation_data = pickle.load(f)\n",
    "\n",
    "    X_train = train_data['features']\n",
    "    y_train = train_data['labels']\n",
    "    X_val = validation_data['features']\n",
    "    y_val = validation_data['labels']\n",
    "\n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "\n",
    "def main(_):\n",
    "    # load bottleneck data\n",
    "    training_file = 'vgg-100/vgg_cifar10_100_bottleneck_features_train.p'\n",
    "    validation_file = 'vgg-100/vgg_cifar10_bottleneck_features_validation.p'\n",
    "    \n",
    "    #Command Line \n",
    "    #X_train, y_train, X_val, y_val = load_bottleneck_data(FLAGS.training_file, FLAGS.validation_file)\n",
    "    X_train, y_train, X_val, y_val = load_bottleneck_data(training_file, validation_file)\n",
    "\n",
    "    print(X_train.shape, y_train.shape)\n",
    "    print(X_val.shape, y_val.shape)\n",
    "\n",
    "    nb_classes = len(np.unique(y_train))\n",
    "\n",
    "    # define model\n",
    "    input_shape = X_train.shape[1:]\n",
    "    inp = Input(shape=input_shape)\n",
    "    x = Flatten()(inp)\n",
    "    x = Dense(nb_classes, activation='softmax')(x)\n",
    "    model = Model(inp, x)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # train model\n",
    "    model.fit(X_train, y_train, epochs=FLAGS.epochs, batch_size=FLAGS.batch_size, validation_data=(X_val, y_val), shuffle=True)\n",
    "\n",
    "\n",
    "# parses flags and calls the `main` function above\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet Example .. Bottleneck Features are pre-trained to optimally run on CPU.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file resnet-100/resnet_cifar10_100_bottleneck_features_train.p\n",
      "Validation file resnet-100/resnet_cifar10_bottleneck_features_validation.p\n",
      "(1000, 1, 1, 2048) (1000, 1)\n",
      "(10000, 1, 1, 2048) (10000, 1)\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 0s - loss: 2.5425 - acc: 0.1290 - val_loss: 2.1992 - val_acc: 0.2250\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 0s - loss: 1.9470 - acc: 0.3290 - val_loss: 1.7524 - val_acc: 0.4010\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 0s - loss: 1.5653 - acc: 0.4690 - val_loss: 1.4960 - val_acc: 0.4936\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 0s - loss: 1.2624 - acc: 0.6090 - val_loss: 1.3029 - val_acc: 0.5661\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 0s - loss: 1.0714 - acc: 0.6840 - val_loss: 1.1779 - val_acc: 0.6097\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.9209 - acc: 0.7220 - val_loss: 1.0873 - val_acc: 0.6358\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.8064 - acc: 0.7580 - val_loss: 1.0189 - val_acc: 0.6586\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.7187 - acc: 0.7860 - val_loss: 0.9735 - val_acc: 0.6742\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.6489 - acc: 0.8270 - val_loss: 0.9412 - val_acc: 0.6829\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.5890 - acc: 0.8440 - val_loss: 0.9095 - val_acc: 0.6915\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.5442 - acc: 0.8630 - val_loss: 0.8906 - val_acc: 0.6989\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.4986 - acc: 0.8750 - val_loss: 0.8755 - val_acc: 0.7029\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.4618 - acc: 0.8940 - val_loss: 0.8604 - val_acc: 0.7081\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.4286 - acc: 0.9090 - val_loss: 0.8505 - val_acc: 0.7079\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.3997 - acc: 0.9180 - val_loss: 0.8399 - val_acc: 0.7139\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.3716 - acc: 0.9240 - val_loss: 0.8326 - val_acc: 0.7137\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.3481 - acc: 0.9370 - val_loss: 0.8266 - val_acc: 0.7163\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.3257 - acc: 0.9440 - val_loss: 0.8206 - val_acc: 0.7181\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.3069 - acc: 0.9500 - val_loss: 0.8170 - val_acc: 0.7189\n",
      "Epoch 20/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.2883 - acc: 0.9620 - val_loss: 0.8148 - val_acc: 0.7208\n",
      "Epoch 21/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.2735 - acc: 0.9690 - val_loss: 0.8127 - val_acc: 0.7210\n",
      "Epoch 22/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.2584 - acc: 0.9750 - val_loss: 0.8085 - val_acc: 0.7205\n",
      "Epoch 23/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.2442 - acc: 0.9780 - val_loss: 0.8049 - val_acc: 0.7221\n",
      "Epoch 24/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.2308 - acc: 0.9800 - val_loss: 0.8033 - val_acc: 0.7226\n",
      "Epoch 25/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.2179 - acc: 0.9850 - val_loss: 0.8049 - val_acc: 0.7239\n",
      "Epoch 26/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.2082 - acc: 0.9860 - val_loss: 0.8018 - val_acc: 0.7239\n",
      "Epoch 27/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.1976 - acc: 0.9880 - val_loss: 0.7987 - val_acc: 0.7246\n",
      "Epoch 28/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.1885 - acc: 0.9890 - val_loss: 0.7980 - val_acc: 0.7257\n",
      "Epoch 29/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.1792 - acc: 0.9920 - val_loss: 0.8005 - val_acc: 0.7259\n",
      "Epoch 30/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.1716 - acc: 0.9920 - val_loss: 0.7982 - val_acc: 0.7256\n",
      "Epoch 31/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.1633 - acc: 0.9930 - val_loss: 0.7954 - val_acc: 0.7259\n",
      "Epoch 32/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.1559 - acc: 0.9950 - val_loss: 0.7955 - val_acc: 0.7261\n",
      "Epoch 33/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.1489 - acc: 0.9970 - val_loss: 0.7967 - val_acc: 0.7253\n",
      "Epoch 34/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.1424 - acc: 0.9970 - val_loss: 0.7963 - val_acc: 0.7258\n",
      "Epoch 35/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.1369 - acc: 0.9970 - val_loss: 0.7958 - val_acc: 0.7274\n",
      "Epoch 36/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.1310 - acc: 0.9980 - val_loss: 0.7940 - val_acc: 0.7268\n",
      "Epoch 37/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.1258 - acc: 0.9980 - val_loss: 0.7951 - val_acc: 0.7257\n",
      "Epoch 38/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.1210 - acc: 0.9980 - val_loss: 0.7952 - val_acc: 0.7273\n",
      "Epoch 39/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.1165 - acc: 0.9980 - val_loss: 0.7951 - val_acc: 0.7286\n",
      "Epoch 40/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.1126 - acc: 0.9980 - val_loss: 0.7961 - val_acc: 0.7279\n",
      "Epoch 41/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.1083 - acc: 0.9980 - val_loss: 0.7957 - val_acc: 0.7276\n",
      "Epoch 42/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.1049 - acc: 0.9980 - val_loss: 0.7961 - val_acc: 0.7291\n",
      "Epoch 43/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.1005 - acc: 0.9990 - val_loss: 0.7960 - val_acc: 0.7284\n",
      "Epoch 44/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.0973 - acc: 1.0000 - val_loss: 0.7960 - val_acc: 0.7285\n",
      "Epoch 45/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.0939 - acc: 1.0000 - val_loss: 0.7973 - val_acc: 0.7284\n",
      "Epoch 46/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.0915 - acc: 1.0000 - val_loss: 0.8008 - val_acc: 0.7288\n",
      "Epoch 47/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.0879 - acc: 1.0000 - val_loss: 0.7974 - val_acc: 0.7300\n",
      "Epoch 48/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.0850 - acc: 1.0000 - val_loss: 0.7975 - val_acc: 0.7292\n",
      "Epoch 49/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.0824 - acc: 1.0000 - val_loss: 0.7984 - val_acc: 0.7305\n",
      "Epoch 50/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.0800 - acc: 1.0000 - val_loss: 0.8008 - val_acc: 0.7303\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "# command line flags\n",
    "# flags.DEFINE_string('training_file', '', \"Bottleneck features training file (.p)\")\n",
    "# flags.DEFINE_string('validation_file', '', \"Bottleneck features validation file (.p)\")\n",
    "# flags.DEFINE_integer('epochs', 50, \"The number of epochs.\")\n",
    "# flags.DEFINE_integer('batch_size', 256, \"The batch size.\")\n",
    "\n",
    "def load_bottleneck_data(training_file, validation_file):\n",
    "    \"\"\"\n",
    "    Utility function to load bottleneck features.\n",
    "\n",
    "    Arguments:\n",
    "        training_file - String\n",
    "        validation_file - String\n",
    "    \"\"\"\n",
    "    print(\"Training file\", training_file)\n",
    "    print(\"Validation file\", validation_file)\n",
    "\n",
    "    with open(training_file, 'rb') as f:\n",
    "        train_data = pickle.load(f)\n",
    "    with open(validation_file, 'rb') as f:\n",
    "        validation_data = pickle.load(f)\n",
    "\n",
    "    X_train = train_data['features']\n",
    "    y_train = train_data['labels']\n",
    "    X_val = validation_data['features']\n",
    "    y_val = validation_data['labels']\n",
    "\n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "\n",
    "def main(_):\n",
    "    # load bottleneck data\n",
    "    training_file = 'resnet-100/resnet_cifar10_100_bottleneck_features_train.p'\n",
    "    validation_file = 'resnet-100/resnet_cifar10_bottleneck_features_validation.p'\n",
    "    \n",
    "    #Command Line \n",
    "    #X_train, y_train, X_val, y_val = load_bottleneck_data(FLAGS.training_file, FLAGS.validation_file)\n",
    "    X_train, y_train, X_val, y_val = load_bottleneck_data(training_file, validation_file)\n",
    "\n",
    "    print(X_train.shape, y_train.shape)\n",
    "    print(X_val.shape, y_val.shape)\n",
    "\n",
    "    nb_classes = len(np.unique(y_train))\n",
    "\n",
    "    # define model\n",
    "    input_shape = X_train.shape[1:]\n",
    "    inp = Input(shape=input_shape)\n",
    "    x = Flatten()(inp)\n",
    "    x = Dense(nb_classes, activation='softmax')(x)\n",
    "    model = Model(inp, x)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # train model\n",
    "    model.fit(X_train, y_train, epochs=FLAGS.epochs, batch_size=FLAGS.batch_size, validation_data=(X_val, y_val), shuffle=True)\n",
    "\n",
    "\n",
    "# parses flags and calls the `main` function above\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GoogLeNet (Inception) Example .. Bottleneck Features are pre-trained to optimally run on CPU.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file inception-100/inception_cifar10_100_bottleneck_features_train.p\n",
      "Validation file inception-100/inception_cifar10_bottleneck_features_validation.p\n",
      "(1000, 1, 1, 2048) (1000, 1)\n",
      "(10000, 1, 1, 2048) (10000, 1)\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 0s - loss: 2.2689 - acc: 0.1740 - val_loss: 1.9632 - val_acc: 0.3038\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 0s - loss: 1.7616 - acc: 0.4060 - val_loss: 1.6507 - val_acc: 0.4399\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 0s - loss: 1.4270 - acc: 0.5700 - val_loss: 1.4468 - val_acc: 0.5214\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 0s - loss: 1.1967 - acc: 0.6620 - val_loss: 1.3126 - val_acc: 0.5647\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 0s - loss: 1.0349 - acc: 0.7070 - val_loss: 1.2248 - val_acc: 0.5916\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.9155 - acc: 0.7400 - val_loss: 1.1646 - val_acc: 0.6084\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.8249 - acc: 0.7660 - val_loss: 1.1229 - val_acc: 0.6219\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.7506 - acc: 0.7930 - val_loss: 1.0925 - val_acc: 0.6307\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.6882 - acc: 0.8220 - val_loss: 1.0696 - val_acc: 0.6373\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.6349 - acc: 0.8430 - val_loss: 1.0526 - val_acc: 0.6432\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.5880 - acc: 0.8560 - val_loss: 1.0401 - val_acc: 0.6492\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.5463 - acc: 0.8720 - val_loss: 1.0309 - val_acc: 0.6511\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.5088 - acc: 0.8860 - val_loss: 1.0240 - val_acc: 0.6542\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.4747 - acc: 0.8950 - val_loss: 1.0183 - val_acc: 0.6565\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.4445 - acc: 0.9120 - val_loss: 1.0140 - val_acc: 0.6572\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.4165 - acc: 0.9200 - val_loss: 1.0111 - val_acc: 0.6591\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.3912 - acc: 0.9270 - val_loss: 1.0084 - val_acc: 0.6603\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.3676 - acc: 0.9370 - val_loss: 1.0068 - val_acc: 0.6611\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.3467 - acc: 0.9460 - val_loss: 1.0060 - val_acc: 0.6599\n",
      "Epoch 20/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.3268 - acc: 0.9510 - val_loss: 1.0050 - val_acc: 0.6611\n",
      "Epoch 21/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.3086 - acc: 0.9540 - val_loss: 1.0041 - val_acc: 0.6599\n",
      "Epoch 22/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.2915 - acc: 0.9620 - val_loss: 1.0041 - val_acc: 0.6589\n",
      "Epoch 23/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.2759 - acc: 0.9670 - val_loss: 1.0045 - val_acc: 0.6585\n",
      "Epoch 24/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.2616 - acc: 0.9700 - val_loss: 1.0046 - val_acc: 0.6596\n",
      "Epoch 25/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.2482 - acc: 0.9750 - val_loss: 1.0050 - val_acc: 0.6584\n",
      "Epoch 26/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.2354 - acc: 0.9780 - val_loss: 1.0056 - val_acc: 0.6585\n",
      "Epoch 27/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.2238 - acc: 0.9810 - val_loss: 1.0060 - val_acc: 0.6580\n",
      "Epoch 28/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.2133 - acc: 0.9880 - val_loss: 1.0069 - val_acc: 0.6582\n",
      "Epoch 29/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.2028 - acc: 0.9890 - val_loss: 1.0079 - val_acc: 0.6577\n",
      "Epoch 30/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.1934 - acc: 0.9920 - val_loss: 1.0094 - val_acc: 0.6572\n",
      "Epoch 31/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.1844 - acc: 0.9930 - val_loss: 1.0105 - val_acc: 0.6580\n",
      "Epoch 32/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.1763 - acc: 0.9940 - val_loss: 1.0116 - val_acc: 0.6583\n",
      "Epoch 33/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.1684 - acc: 0.9950 - val_loss: 1.0132 - val_acc: 0.6577\n",
      "Epoch 34/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.1613 - acc: 0.9950 - val_loss: 1.0146 - val_acc: 0.6583\n",
      "Epoch 35/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.1543 - acc: 0.9970 - val_loss: 1.0163 - val_acc: 0.6577\n",
      "Epoch 36/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.1481 - acc: 0.9980 - val_loss: 1.0175 - val_acc: 0.6582\n",
      "Epoch 37/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.1421 - acc: 0.9980 - val_loss: 1.0189 - val_acc: 0.6582\n",
      "Epoch 38/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.1364 - acc: 0.9990 - val_loss: 1.0206 - val_acc: 0.6579\n",
      "Epoch 39/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.1312 - acc: 0.9990 - val_loss: 1.0224 - val_acc: 0.6584\n",
      "Epoch 40/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.1262 - acc: 0.9990 - val_loss: 1.0243 - val_acc: 0.6585\n",
      "Epoch 41/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.1216 - acc: 0.9990 - val_loss: 1.0261 - val_acc: 0.6581\n",
      "Epoch 42/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.1171 - acc: 1.0000 - val_loss: 1.0274 - val_acc: 0.6581\n",
      "Epoch 43/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.1129 - acc: 1.0000 - val_loss: 1.0291 - val_acc: 0.6585\n",
      "Epoch 44/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.1090 - acc: 1.0000 - val_loss: 1.0307 - val_acc: 0.6591\n",
      "Epoch 45/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.1053 - acc: 1.0000 - val_loss: 1.0324 - val_acc: 0.6592\n",
      "Epoch 46/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.1018 - acc: 1.0000 - val_loss: 1.0342 - val_acc: 0.6600\n",
      "Epoch 47/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.0984 - acc: 1.0000 - val_loss: 1.0359 - val_acc: 0.6596\n",
      "Epoch 48/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.0953 - acc: 1.0000 - val_loss: 1.0375 - val_acc: 0.6598\n",
      "Epoch 49/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.0923 - acc: 1.0000 - val_loss: 1.0394 - val_acc: 0.6596\n",
      "Epoch 50/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.0895 - acc: 1.0000 - val_loss: 1.0410 - val_acc: 0.6597\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "# command line flags\n",
    "# flags.DEFINE_string('training_file', '', \"Bottleneck features training file (.p)\")\n",
    "# flags.DEFINE_string('validation_file', '', \"Bottleneck features validation file (.p)\")\n",
    "# flags.DEFINE_integer('epochs', 50, \"The number of epochs.\")\n",
    "# flags.DEFINE_integer('batch_size', 256, \"The batch size.\")\n",
    "\n",
    "def load_bottleneck_data(training_file, validation_file):\n",
    "    \"\"\"\n",
    "    Utility function to load bottleneck features.\n",
    "\n",
    "    Arguments:\n",
    "        training_file - String\n",
    "        validation_file - String\n",
    "    \"\"\"\n",
    "    print(\"Training file\", training_file)\n",
    "    print(\"Validation file\", validation_file)\n",
    "\n",
    "    with open(training_file, 'rb') as f:\n",
    "        train_data = pickle.load(f)\n",
    "    with open(validation_file, 'rb') as f:\n",
    "        validation_data = pickle.load(f)\n",
    "\n",
    "    X_train = train_data['features']\n",
    "    y_train = train_data['labels']\n",
    "    X_val = validation_data['features']\n",
    "    y_val = validation_data['labels']\n",
    "\n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "\n",
    "def main(_):\n",
    "    # load bottleneck data\n",
    "    training_file = 'inception-100/inception_cifar10_100_bottleneck_features_train.p'\n",
    "    validation_file = 'inception-100/inception_cifar10_bottleneck_features_validation.p'\n",
    "    \n",
    "    #Command Line \n",
    "    #X_train, y_train, X_val, y_val = load_bottleneck_data(FLAGS.training_file, FLAGS.validation_file)\n",
    "    X_train, y_train, X_val, y_val = load_bottleneck_data(training_file, validation_file)\n",
    "\n",
    "    print(X_train.shape, y_train.shape)\n",
    "    print(X_val.shape, y_val.shape)\n",
    "\n",
    "    nb_classes = len(np.unique(y_train))\n",
    "\n",
    "    # define model\n",
    "    input_shape = X_train.shape[1:]\n",
    "    inp = Input(shape=input_shape)\n",
    "    x = Flatten()(inp)\n",
    "    x = Dense(nb_classes, activation='softmax')(x)\n",
    "    model = Model(inp, x)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # train model\n",
    "    model.fit(X_train, y_train, epochs=FLAGS.epochs, batch_size=FLAGS.batch_size, validation_data=(X_val, y_val), shuffle=True)\n",
    "\n",
    "\n",
    "# parses flags and calls the `main` function above\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
